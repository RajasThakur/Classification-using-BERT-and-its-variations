{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "## Loading Dataset\n",
    "\n",
    "We will use The 20 Newsgroups dataset \n",
    "Dataset [homepage](http://qwone.com/~jason/20Newsgroups/): \n",
    "\n",
    "Scikit-learn includes some nice helper functions for retrieving the 20 Newsgroups dataset-- https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html. We'll use them below to retrieve the dataset.\n",
    "\n",
    "Also look at results fron non- neural net models here : https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h_mxTHPHCywo",
    "outputId": "468900f9-30e8-4fee-fd88-331a48c7c77f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 8.1MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.9.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 39.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 24.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=b2aa34486492d08311edeba2f749a015074c06c577e7185c875106a6aa87ae0e\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vmTYekyqtSz"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout \n",
    "np.random.seed(0) \n",
    "from pathlib import Path\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torchtext.data as ttd\n",
    "import transformers as ppb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXScUokPqyPx",
    "outputId": "6ae595a1-5459-4d32-bea1-81e5b02edd1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "train = fetch_20newsgroups(subset='train',\n",
    "                           remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "test = fetch_20newsgroups(subset='test',\n",
    "                           remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3NS-Vxi0Pkt-",
    "outputId": "acbf2ba0-da46-42f6-e185-ee06a69a2651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jV2eF-BiPrLZ",
    "outputId": "863321cd-fd8f-474e-9618-daa011cafcc6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(train.target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IqtsBCEPx-E",
    "outputId": "ccaa446f-23a8-493f-a331-d6c98c1ab774"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u3v7ZzA2QHv6",
    "outputId": "5c5af45a-3e75-4c2c-89df-d32dd1ea97f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "0NiOeWmbRV_G",
    "outputId": "dbef2b52-f993-4e2b-b381-c122305c0069"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Plot the number of tokens of each length.\n",
    "sns.countplot(train.target);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCGrer1M5QUt",
    "outputId": "9a2ed275-a3e0-4f61-a80d-9ef38d1fdaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    11314 non-null  object\n",
      " 1   target  11314 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 176.9+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7532 entries, 0 to 7531\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7532 non-null   object\n",
      " 1   target  7532 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.8+ KB\n"
     ]
    }
   ],
   "source": [
    "#Saving Data into Dataframe\n",
    "train = pd.DataFrame([train.data, train.target.tolist()]).T\n",
    "train.columns = ['text', 'target']\n",
    "test = pd.DataFrame([test.data, test.target.tolist()]).T\n",
    "test.columns = ['text', 'target']\n",
    "train.info()\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXleu6KE6p5L",
    "outputId": "ff9d340f-8646-417d-b154-e554d19601a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4, 1, 14, 16, 13, 3, 2, 8, 19, 6, 0, 12, 5, 10, 9, 15, 17, 18,\n",
       "       11], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7BgojJQ8D97U"
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"train.csv\",index=False)\n",
    "test.to_csv(\"test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hmCyX6aTj5ua"
   },
   "source": [
    "# Task 1- Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaWZaV2WCAwW"
   },
   "source": [
    "## Tokenization- Task 1 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "audktyPyfELm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "5f6c04b440804499a91c06603272cd12",
      "60d2b433f3274e8c9c83606b87325f3c",
      "c0ae83c9b3c44993a0622b4cce1823ec",
      "af436f5b83aa4e5ca0bd59286226d54f",
      "1233d9b2c340408992071a3903decfae",
      "c2bc8aab01a24f51a8fe433422ec53e8",
      "3186856ad0024e4886ab0a59fbcc767f",
      "0c7478b09e6644a59c7694028224ae36"
     ]
    },
    "id": "qFG9tSMuBMDA",
    "outputId": "a4484a23-414b-486f-afdc-a15fb5d9994f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6c04b440804499a91c06603272cd12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcahdFTfCN0o"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[:max_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVj1weIfCagY"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Khyw4V4ECnYQ"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WH_AdplNEnkS"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7C8GXPZPJD_z"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hp48IXAdFDLh"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jdmpiv9DJPSC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Z0_mVvOHxih",
    "outputId": "f3fb2494-533c-452e-eb93-ec8349011d92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c9Aeveg2Kmz5"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(data_iter, model):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    correct =0 \n",
    "    total =0\n",
    "    \n",
    "    for batch in data_iter:\n",
    "\n",
    "      output=model(batch.data)\n",
    "      _,indices = torch.max(output,dim=1)\n",
    "      correct+= (batch.label==indices).sum().item()\n",
    "      total += batch.label.shape[0]\n",
    "    \n",
    "    acc= correct/total\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrIrT40mKU1X"
   },
   "source": [
    "### RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6AcoIhLMK0Kn"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
    "      super(RNN, self).__init__()\n",
    "      self.D = bert_model.config.to_dict()['hidden_size']\n",
    "      self.bert_model = bert_model\n",
    "      \n",
    "      self.M = n_hidden\n",
    "      self.K = n_outputs\n",
    "      self.L = n_rnnlayers\n",
    "      self.num_diections= bidirectional\n",
    "      self.dropout_rate=dropout_rate\n",
    "      \n",
    "\n",
    "      \n",
    "      # rnn layers\n",
    "      self.rnn = nn.LSTM(\n",
    "          input_size=self.D,\n",
    "          hidden_size=self.M,\n",
    "          num_layers=self.L,\n",
    "          bidirectional=self.num_diections,\n",
    "          dropout= self.dropout_rate,\n",
    "          batch_first=True)\n",
    "      \n",
    "      # dense layer\n",
    "      self.fc = nn.Linear(self.M *2 , self.K)\n",
    "\n",
    "      # dropout layer\n",
    "      self.dropout= nn.Dropout(self.dropout_rate)\n",
    "    \n",
    "    def forward(self, X):\n",
    "      # initial hidden states\n",
    "      h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "      c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "\n",
    "\n",
    "      with torch.no_grad():\n",
    "        embedding = self.bert_model(X)[0][:,1:,:]\n",
    "\n",
    "      embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
    "\n",
    "      # get RNN unit output\n",
    "      output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
    "\n",
    "\n",
    "\n",
    "      # max pool\n",
    "      output, _ = torch.max(output, 1)\n",
    "      output= self.dropout(output)\n",
    "      # we only want h(T) at the final time step\n",
    "      output = self.fc(output)\n",
    "      return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSOD31xdM7HD"
   },
   "source": [
    "### **BERT** Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7_C4VC_jLcNw",
    "outputId": "6adea9d5-89cb-4a35-aa6a-d93e1a27b774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.8713    Valid Loss: 1.2992, Duration: 0:07:25.556759\n",
      "\n",
      "\n",
      "Train acc: 0.5418,\t Valid acc: 0.5475,\t Test acc: 0.5169\n"
     ]
    }
   ],
   "source": [
    " from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1a.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VABLY8JCaCDP"
   },
   "source": [
    "## Tokenization Task-1 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDO4bWSGfFgd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elysZnyravIt",
    "outputId": "4eafec6c-0e59-43e2-ea3a-059d8bc3f22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4vnqJ_6Zxwv"
   },
   "source": [
    "### Truncating sequence length to 128 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQYBgS4eavIx"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[:128-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ko4TMk2favIx"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99V5lHWlavIx"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvlZF1iOavIx"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDUpBX6-avIx"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DHpXHD8avIx"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XJGuzXoavIx"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mxa_OQvNavIx",
    "outputId": "34d1b6b6-ccfe-4662-f5a9-497b7e72f391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gz1ijGVcawpZ",
    "outputId": "a2dd908d-b3f6-4747-8249-84ee22b204a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.7744    Valid Loss: 1.3200, Duration: 0:01:52.326694\n",
      "\n",
      "\n",
      "Train acc: 0.5708,\t Valid acc: 0.5444,\t Test acc: 0.5319\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1b.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHUQS6JCd-oK"
   },
   "source": [
    "## Tokenization Task-1 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBNam254fGgn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SeQhZcQ6eI_f",
    "outputId": "12e0ba6d-392f-45f1-c0b3-20e1d439547f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vd-uemq9Z9ZX"
   },
   "source": [
    "### Truncate sequence length to 140 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HDfF7f0yeI_i"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[:140-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqrEcopzeI_i"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "loQVQKhTeI_j"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCKOucgHeI_j"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4HPHcg_eI_k"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZ4oxPHFeI_k"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2dXkLlXeI_k"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lm2nUllueI_k",
    "outputId": "440be6b2-fa9b-433e-c7a7-0d53dd121a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-QZnVh2eI_l",
    "outputId": "d46402fe-f6a6-4953-fad5-491b0610e1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.8199    Valid Loss: 1.3075, Duration: 0:02:08.855693\n",
      "\n",
      "\n",
      "Train acc: 0.5676,\t Valid acc: 0.5541,\t Test acc: 0.5327\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1c.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTDqK-EYeI_m"
   },
   "source": [
    "## Tokenization Task-1 D a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVhxw3hAfHeg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oA75tia9fwWc",
    "outputId": "901166c4-3e0f-44d0-c007-a5e6ebdae19d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jfsxMDNQfwWd"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[-(512-2):]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRzNcy8efwWe"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gn8E5adefwWe"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ufvz1_dqfwWe"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PmdEh5TlfwWe"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnoN_w9KfwWe"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqD29x-dfwWe"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CpIspuWZfwWf",
    "outputId": "0f755286-317c-4cbd-8bc0-ad224f88e2a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pGDgw36NfwWf",
    "outputId": "8ad75d7c-d031-42f6-d1c1-15e90459e079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.8935    Valid Loss: 1.3229, Duration: 0:07:29.703213\n",
      "\n",
      "\n",
      "Train acc: 0.5209,\t Valid acc: 0.5135,\t Test acc: 0.4926\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1da.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtWnky-sfwWf"
   },
   "source": [
    "## Tokenization Task-1 D b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tuV_9VAMfIU1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEvAAsh8gRKr",
    "outputId": "37dea321-fba5-4407-8822-5ec966149ae7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZWSoD0qgRKr"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[-(128-2):]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StcU2jFCgRKr"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FT38PXBFgRKs"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFgruhy2gRKs"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB2JkjurgRKs"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Q-N2C-JgRKs"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XqJ8D4FOgRKs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sWtiHp1gRKs",
    "outputId": "6ba8088a-9de5-463f-e0bf-612f7ff847fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFb_Qwt1gRKs",
    "outputId": "664aa867-a2eb-4413-aebb-3501d7144082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.8446    Valid Loss: 1.3997, Duration: 0:01:53.406713\n",
      "\n",
      "\n",
      "Train acc: 0.5268,\t Valid acc: 0.5210,\t Test acc: 0.4944\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1db.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huACUSnNgRKs"
   },
   "source": [
    "## Tokenization Task-1 D c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cx9_8rYVfI_1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDdlnWPIhIWt",
    "outputId": "8c553ec0-3b9a-485a-a06e-5b844fc0a2ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 92,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqeMsL6KhIWu"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[-(140-2):]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4unVNM_9hIWx"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tP8qezJ0hIWx"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWG_QEN0hIWy"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qk1QIAVYhIWy"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6HRM9whhIWy"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybSzPMgxhIWy"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUSvH1jahIWy",
    "outputId": "eb266db8-5cf6-4669-8372-4d2c7cf6f957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VDMY4FRShIWz",
    "outputId": "d9b2d30f-9b55-49d8-ee38-86e115ec2823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.8393    Valid Loss: 1.4000, Duration: 0:02:09.478683\n",
      "\n",
      "\n",
      "Train acc: 0.5334,\t Valid acc: 0.5276,\t Test acc: 0.5066\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1dc.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEQ61GKYhIWz"
   },
   "source": [
    "## Tokenization Task-1 E a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqIjCxcXfJ4T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j1utvMNehagY",
    "outputId": "e0504d58-e659-4d0a-86d9-950a9bc3a7a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y5bQXvCPhaga"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:256-1]\n",
    "    tokens2 = tokens[-(256-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI4JK9SNhaga"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RN8JS8IPhaga"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CwJCB-QDhagb"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2WVbS2yhagb"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dv2kz1Nxhagb"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iBun92mhagb"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMEWU5U0hagb",
    "outputId": "bd4969a2-826d-4ae0-b4bf-2a0aef183364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbxFNkUAhagb",
    "outputId": "8105f37b-b00c-4f07-db31-f9861f7000a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.9144    Valid Loss: 1.3593, Duration: 0:08:09.085311\n",
      "\n",
      "\n",
      "Train acc: 0.5322,\t Valid acc: 0.5303,\t Test acc: 0.5005\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1ea.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJH5US0ohagc"
   },
   "source": [
    "## Tokenization Task-1 E b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCNYUTrTfKrl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcc-AkNriCgn",
    "outputId": "623734d8-c0e4-4d49-fcc8-0a16e690abe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YjPmmIiiCgn"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:64-1]\n",
    "    tokens2 = tokens[-(64-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nh3k1wM4iCgo"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Ufxt4EIiCgo"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EMIgOV53iCgo"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1dGWcSdiCgo"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLLMqR2HiCgo"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMga2Ls0iCgo"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpCae1moiCgo",
    "outputId": "935a9d63-4953-4f3d-82f9-4ccf64d042a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYsqBnlsiCgo",
    "outputId": "420f00d1-a11c-4cea-a2f2-875a80333e8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.7493    Valid Loss: 1.2400, Duration: 0:01:56.164750\n",
      "\n",
      "\n",
      "Train acc: 0.5955,\t Valid acc: 0.5851,\t Test acc: 0.5647\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1eb.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8Ow2t_iiCgp"
   },
   "source": [
    "## Tokenization Task-1 E c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqoDsgCYiUo1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvMRxpq1ij3S",
    "outputId": "4ab6ce31-38e7-41df-9ceb-3e9c9b35dbe0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmD1f6r6ij3T"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7wmxe8iij3T"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qk06qClQij3T"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plrchOauij3T"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reM_eLSIij3T"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NUnbMFE0ij3T"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0VyxJRCpij3T"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S10D4QgPij3T",
    "outputId": "cfbb1f94-aeb0-420d-8395-50e21a9a06c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SDK1u5imij3T",
    "outputId": "619e4a97-ed74-4b31-e104-c6ccdd73e819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.7707    Valid Loss: 1.2479, Duration: 0:02:12.147152\n",
      "\n",
      "\n",
      "Train acc: 0.5828,\t Valid acc: 0.5722,\t Test acc: 0.5516\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1ec.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FpjZrSuij3U"
   },
   "source": [
    "## Task-1 F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Na8maD2ajMiG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51ipqiKLkdjj"
   },
   "outputs": [],
   "source": [
    "def chunking(data_frame):\n",
    "  #ccreate data frame for chunks\n",
    "  chunks = pd.DataFrame()\n",
    "  chunks['text'] = [] \n",
    "  chunks['target'] = [] \n",
    "  \n",
    "  \n",
    "  for k in range(0,len(data_frame)):\n",
    "    \n",
    "    if len(data_frame.text[k]) > 140:\n",
    "      list = [data_frame.text[k][i: i + 140] for i in range(0, len(data_frame.text[k]), 140)]\n",
    "      \n",
    "      for j in range(0,len(list)):\n",
    "        chunks = chunks.append({'text' : list[j]  ,  'target': data_frame.target[k]}, \n",
    "                  ignore_index = True)\n",
    "   \n",
    "\n",
    "  \n",
    "  chunks.target = chunks.target.astype(int)\n",
    "  return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "LIQs1fr5kdjj",
    "outputId": "0d66546e-3f93-4da7-fb38-aea0ff35909d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erences are far as features or performance. I ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>than book value can you usually get them for....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g\\nearly summer is the best time to buy.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  I am a little confused on all of the models of...       7\n",
       "1  erences are far as features or performance. I ...       7\n",
       "2   than book value can you usually get them for....       7\n",
       "3           g\\nearly summer is the best time to buy.       7\n",
       "4  I'm not familiar at all with the format of the...       5"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chunking = chunking(train)\n",
    "train_chunking.head()\n",
    "test_chunking = chunking(test)\n",
    "test_chunking.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hVb8jXjm3lGt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxrnZ8wikdjm"
   },
   "outputs": [],
   "source": [
    "train_chunking.to_csv(\"train_final.csv\",index=False)\n",
    "test_chunking.to_csv(\"test_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "9eb3fae3298f41b6916f3baa32e12ad1",
      "4d92a8a3d9914efe9e7d62840595c3bc",
      "e4f1266b60424f09abdebaaf28700ef1",
      "16e5ba22bd8246d28e7d292b4ab31e31",
      "e2a292b6a9a649ca901ed989a7060517",
      "cedc361a06614b44a693817654ef0ff1",
      "ad8e78b4c3924f4691f1eae88c3158d7",
      "ae20b7c9834541ebbffcd0b6ad5ec768"
     ]
    },
    "id": "TSC_K8Lokdjm",
    "outputId": "d4d8e358-0c97-44f1-f9f1-bb78d9744274"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb3fae3298f41b6916f3baa32e12ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pdwafjzgkdjn"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens = tokens[:max_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KlGPkokHkdjn"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAOUWvr7kdjn"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6CaV_qbkdjn"
   },
   "outputs": [],
   "source": [
    "    train_dataset = ttd.TabularDataset(\n",
    "        'train_final.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfQYAHD0kdjn"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuIyG65_kdjn"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test_final.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dStcyTTjkdjn"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D6fG_Rnckdjn",
    "outputId": "6cab0424-2ffa-4b73-deb0-429231070f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnGkJPZ2kdjo"
   },
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183,
     "referenced_widgets": [
      "54104c04c82f4478882806cf224e1863",
      "79e74b279e6e4e50b607ac2cb807efd7",
      "b316542b90ad46ab8313f1b64d2d4f73",
      "d80f5624d5e646e29c298bc3703a54e0",
      "79c117e842e24c9da587b602ebb0128c",
      "205f4b27f7d9481c893bd3a730e0d81f",
      "4116a13f25f64873a737bdd5c78f54e8",
      "ebf8642f3cde47be972a8309addc480f",
      "640a5b1585724de78c26593269c31bf5",
      "3121756c6bbf4d7da320f3b6b7b9241c",
      "f21b73ce32114c6b950da3107b91509b",
      "d21b670cde1a40e78dc9fdc8fa033c3f",
      "09ef3bbd5210439aaf9bbc25bdbabcc2",
      "7c422a79ba164e5cb5046d014e4a13ea",
      "477bba3b26584de9a479d927bf4c7165",
      "f9743662f21c4276987c2764115621ce"
     ]
    },
    "id": "1uvJ9kInkdjo",
    "outputId": "90ac7232-323c-4dbc-c25b-ea3e58a7b7fe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54104c04c82f4478882806cf224e1863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640a5b1585724de78c26593269c31bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5, Train Loss: 1.9068    Valid Loss: 1.3343, Duration: 0:07:45.576905\n",
      "\n",
      "\n",
      "Train acc: 0.5357,\t Valid acc: 0.5422,\t Test acc: 0.5101\n"
     ]
    }
   ],
   "source": [
    " from transformers import  BertModel\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1f.pt')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "QoL80QIWpOLQ",
    "outputId": "a0184bc0-007a-46f3-fb42-466913540abc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am a little confused on all of the models of...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erences are far as features or performance. I ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>than book value can you usually get them for....</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g\\nearly summer is the best time to buy.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm not familiar at all with the format of the...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  I am a little confused on all of the models of...       7\n",
       "1  erences are far as features or performance. I ...       7\n",
       "2   than book value can you usually get them for....       7\n",
       "3           g\\nearly summer is the best time to buy.       7\n",
       "4  I'm not familiar at all with the format of the...       5"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_chunking = chunking(train)\n",
    "train_chunking.head()\n",
    "test_chunking = chunking(test)\n",
    "test_chunking.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IKTjr-grpOLS"
   },
   "outputs": [],
   "source": [
    "train_chunking.to_csv(\"train_final.csv\",index=False)\n",
    "test_chunking.to_csv(\"test_final.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhaPICY0olTw"
   },
   "source": [
    "# Task 1- Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12WZ9FRCpOLS"
   },
   "source": [
    "## Tokenization- Task 1 a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "887d172b7fb64478b06eceb5dfbda5a1",
      "0c4b526b07164a4ca784e8382ff91e6c",
      "477a10aeadc241d2a3169f208090a20a",
      "6f041b126599482a8f9664c61531278f",
      "d6c36207a1fa48fb88660c89fae2c77f",
      "f9534f0f1e5b4667a143cf1d448811e9",
      "30bc9a8e56b2420bb0743665ec2d643d",
      "f5a49914513b44b9b73d1ac8d0cb756d"
     ]
    },
    "id": "4skB5cFHpOLS",
    "outputId": "52b21feb-cc11-424b-be79-fa3aaa5e7bb3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887d172b7fb64478b06eceb5dfbda5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import BertTokenizer\n",
    "  tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FWG8L7xqpOLS"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcGMk86qpOLT"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cL22ScMzpOLT"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vFCF1BMpOLT"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjbc9FB1pOLT"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82garK6_pOLT"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc1Orm3IpOLU"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WpLQiVLFpOLU",
    "outputId": "86e8ffcd-6041-4eaf-e71f-721543a0a169"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQgpipJOpOLU"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(data_iter, model):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    correct =0 \n",
    "    total =0\n",
    "    \n",
    "    for batch in data_iter:\n",
    "\n",
    "      output=model(batch.data)\n",
    "      _,indices = torch.max(output,dim=1)\n",
    "      correct+= (batch.label==indices).sum().item()\n",
    "      total += batch.label.shape[0]\n",
    "    \n",
    "    acc= correct/total\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gTIvayLwpOLV"
   },
   "source": [
    "#### Defining the RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dNajDDakpOLV"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
    "      super(RNN, self).__init__()\n",
    "      self.D = bert_model.config.to_dict()['hidden_size']\n",
    "      self.bert_model = bert_model\n",
    "      \n",
    "      self.M = n_hidden\n",
    "      self.K = n_outputs\n",
    "      self.L = n_rnnlayers\n",
    "      self.num_diections= bidirectional\n",
    "      self.dropout_rate=dropout_rate\n",
    "      \n",
    "\n",
    "      \n",
    "      # rnn layers\n",
    "      self.rnn = nn.LSTM(\n",
    "          input_size=self.D,\n",
    "          hidden_size=self.M,\n",
    "          num_layers=self.L,\n",
    "          bidirectional=self.num_diections,\n",
    "          dropout= self.dropout_rate,\n",
    "          batch_first=True)\n",
    "      \n",
    "      # dense layer\n",
    "      self.fc = nn.Linear(self.M *2 , self.K)\n",
    "\n",
    "      # dropout layer\n",
    "      self.dropout= nn.Dropout(self.dropout_rate)\n",
    "    \n",
    "    def forward(self, X):\n",
    "      # initial hidden states\n",
    "      h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "      c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "\n",
    "\n",
    "      with torch.no_grad():\n",
    "        embedding = self.bert_model(X)[0][:,1:,:]\n",
    "\n",
    "      embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
    "\n",
    "      # get RNN unit output\n",
    "      output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
    "\n",
    "\n",
    "\n",
    "      # max pool\n",
    "      output, _ = torch.max(output, 1)\n",
    "      output= self.dropout(output)\n",
    "      # we only want h(T) at the final time step\n",
    "      output = self.fc(output)\n",
    "      return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThuqUQfgpOLV"
   },
   "source": [
    "#### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P9yTkL-WpOLV",
    "outputId": "6971f0c3-560a-4c58-b88f-7e06bc682b44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 1.8177    Valid Loss: 1.4162, Duration: 0:02:17.977619\n",
      "Validation loss decreased (inf --> 1.416152).  Saving model ...\n",
      "Epoch 2/33, Train Loss: 1.2211    Valid Loss: 1.1603, Duration: 0:02:17.296153\n",
      "Validation loss decreased (1.416152 --> 1.160272).  Saving model ...\n",
      "Epoch 3/33, Train Loss: 1.0363    Valid Loss: 1.0394, Duration: 0:02:17.467400\n",
      "Validation loss decreased (1.160272 --> 1.039366).  Saving model ...\n",
      "Epoch 4/33, Train Loss: 0.9046    Valid Loss: 1.0349, Duration: 0:02:17.325978\n",
      "Validation loss decreased (1.039366 --> 1.034854).  Saving model ...\n",
      "Epoch 5/33, Train Loss: 0.7935    Valid Loss: 1.0429, Duration: 0:02:17.375532\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 6/33, Train Loss: 0.7001    Valid Loss: 1.0007, Duration: 0:02:17.285221\n",
      "Validation loss decreased (1.034854 --> 1.000709).  Saving model ...\n",
      "Epoch 7/33, Train Loss: 0.6231    Valid Loss: 1.0121, Duration: 0:02:17.325661\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 8/33, Train Loss: 0.5253    Valid Loss: 0.9897, Duration: 0:02:17.289058\n",
      "Validation loss decreased (1.000709 --> 0.989659).  Saving model ...\n",
      "Epoch 9/33, Train Loss: 0.4611    Valid Loss: 1.0350, Duration: 0:02:17.275583\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 10/33, Train Loss: 0.3993    Valid Loss: 1.0937, Duration: 0:02:17.257047\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 11/33, Train Loss: 0.3437    Valid Loss: 1.1058, Duration: 0:02:17.245032\n",
      "Early Stopping counter: 3 out of 5\n",
      "Epoch 12/33, Train Loss: 0.2935    Valid Loss: 1.1589, Duration: 0:02:17.360719\n",
      "Early Stopping counter: 4 out of 5\n",
      "Epoch 13/33, Train Loss: 0.2592    Valid Loss: 1.1830, Duration: 0:02:17.369855\n",
      "Early Stopping counter: 5 out of 5\n",
      "Early stopping\n",
      "\n",
      "\n",
      "Train acc: 0.8957,\t Valid acc: 0.7150,\t Test acc: 0.6632\n"
     ]
    }
   ],
   "source": [
    "from transformers import  BertModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) ## 5\n",
    "\n",
    "\n",
    "\n",
    "  ## 6. Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 33\n",
    "\n",
    "  #early stop para,eters\n",
    "patience = 5\n",
    "counter_early_stop = 0\n",
    "best_score = None\n",
    "early_stop = False\n",
    "valid_loss_min = np.Inf\n",
    "delta=0.001  \n",
    "\n",
    "# STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_iter) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "\n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "  model.train()\n",
    "  for batch in train_iter:\n",
    "    \n",
    "      # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "\n",
    "    # set gradients to zero \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    train_loss.append(loss.item())\n",
    "    \n",
    "  train_loss=np.mean(train_loss)\n",
    "        \n",
    "  valid_loss=[]\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "      output= model(batch.data)\n",
    "      loss=criterion(output,batch.label)\n",
    "        \n",
    "      valid_loss.append(loss.item())\n",
    "\n",
    "    valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "  train_losses[epoch]= train_loss\n",
    "  valid_losses[epoch]= valid_loss\n",
    "  dt= datetime.now()-t0\n",
    "    #print(scheduler)\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "\n",
    "    ## Early Stopping\n",
    "  score = -valid_loss\n",
    "\n",
    "  if best_score is None:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      valid_loss_min = valid_loss\n",
    "        \n",
    "  elif score < best_score + delta:\n",
    "      counter_early_stop += 1\n",
    "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
    "      if counter_early_stop >= patience:\n",
    "          early_stop = True\n",
    "  else:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      counter_early_stop = 0\n",
    "      valid_loss_min = valid_loss\n",
    "\n",
    "  if early_stop:\n",
    "    print(\"Early stopping\")\n",
    "    break\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  #load model\n",
    "model.load_state_dict(torch.load('tuned_bert.pt'))\n",
    "train_acc = get_accuracy(train_iter, model)\n",
    "valid_acc = get_accuracy(valid_iter, model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JlsE9DFwpOLW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Osxgj3_Nnwo"
   },
   "source": [
    "# Task 1- Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIoxBUQ_jN8_"
   },
   "source": [
    "#### For this experiment, we have considered these two variations of BERT from Huggingface library : Roberta and MobileBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pNak9cHh4Vs"
   },
   "source": [
    "## Running Roberta without fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0cJaJ6jiPJk",
    "outputId": "f64ef03c-a0d0-4f8e-de69-44a99c7626b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import RobertaTokenizer\n",
    "  tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_buiGqPKiPJm"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAdn0PmsiPJm"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eivJanfiPJm"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g3RAmgx4iPJm"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mCZnxmOiPJm"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cupAsxDYiPJm"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DGZ2u1TiPJm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TmF--RvWiPJm",
    "outputId": "14367874-d8c5-4a10-9833-dbd1661e60fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SGsT6AtQiPJn",
    "outputId": "5d335684-0f5f-4199-8479-a548d711a495"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 2.0210    Valid Loss: 1.4290, Duration: 0:02:19.126410\n",
      "\n",
      "\n",
      "Train acc: 0.4935,\t Valid acc: 0.4896,\t Test acc: 0.4772\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "bert_model = RobertaModel.from_pretrained('roberta-base')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1ec.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VIx243rNwFn"
   },
   "source": [
    "## Running Fine tuned model - Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dU3evFW0Nyut"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M5v6OTFDQH4l",
    "outputId": "a824ac62-9d91-452a-8668-c918da513d64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  from transformers import RobertaTokenizer\n",
    "  tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "  max_length = tokenizer.model_max_length\n",
    "  max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gw3C3RINQH4l"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BiD-ggOkQH4l"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LAlMsonEQH4l"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zkOmNH4XQH4l"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECNczyCzQH4l"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1P3jBOp1QH4l"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g--hsZc0QH4l"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HX_g2zxxQH4l",
    "outputId": "26bf54db-914d-4b20-c8f8-443972b52afb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0hbvtczQH4l"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(data_iter, model):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    correct =0 \n",
    "    total =0\n",
    "    \n",
    "    for batch in data_iter:\n",
    "\n",
    "      output=model(batch.data)\n",
    "      _,indices = torch.max(output,dim=1)\n",
    "      correct+= (batch.label==indices).sum().item()\n",
    "      total += batch.label.shape[0]\n",
    "    \n",
    "    acc= correct/total\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lcHFlh-5QH4m"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
    "      super(RNN, self).__init__()\n",
    "      self.D = bert_model.config.to_dict()['hidden_size']\n",
    "      self.bert_model = bert_model\n",
    "      \n",
    "      self.M = n_hidden\n",
    "      self.K = n_outputs\n",
    "      self.L = n_rnnlayers\n",
    "      self.num_diections= bidirectional\n",
    "      self.dropout_rate=dropout_rate\n",
    "      \n",
    "\n",
    "      \n",
    "      # rnn layers\n",
    "      self.rnn = nn.LSTM(\n",
    "          input_size=self.D,\n",
    "          hidden_size=self.M,\n",
    "          num_layers=self.L,\n",
    "          bidirectional=self.num_diections,\n",
    "          dropout= self.dropout_rate,\n",
    "          batch_first=True)\n",
    "      \n",
    "      # dense layer\n",
    "      self.fc = nn.Linear(self.M *2 , self.K)\n",
    "\n",
    "      # dropout layer\n",
    "      self.dropout= nn.Dropout(self.dropout_rate)\n",
    "    \n",
    "    def forward(self, X):\n",
    "      # initial hidden states\n",
    "      h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "      c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "\n",
    "\n",
    "      with torch.no_grad():\n",
    "        embedding = self.bert_model(X)[0][:,1:,:]\n",
    "\n",
    "      embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
    "\n",
    "      # get RNN unit output\n",
    "      output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
    "\n",
    "\n",
    "\n",
    "      # max pool\n",
    "      output, _ = torch.max(output, 1)\n",
    "      output= self.dropout(output)\n",
    "      # we only want h(T) at the final time step\n",
    "      output = self.fc(output)\n",
    "      return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lrFz5akaQH4m"
   },
   "source": [
    "### Roberta Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4TGx354QH4m",
    "outputId": "34314513-5728-4f9c-ef3a-06697ac7be1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33, Train Loss: 1.9895    Valid Loss: 1.3830, Duration: 0:02:19.569034\n",
      "Validation loss decreased (inf --> 1.382996).  Saving model ...\n",
      "Epoch 2/33, Train Loss: 1.3634    Valid Loss: 1.2364, Duration: 0:02:18.860085\n",
      "Validation loss decreased (1.382996 --> 1.236416).  Saving model ...\n",
      "Epoch 3/33, Train Loss: 1.1812    Valid Loss: 1.1305, Duration: 0:02:18.937191\n",
      "Validation loss decreased (1.236416 --> 1.130453).  Saving model ...\n",
      "Epoch 4/33, Train Loss: 1.0298    Valid Loss: 1.0170, Duration: 0:02:18.920303\n",
      "Validation loss decreased (1.130453 --> 1.017023).  Saving model ...\n",
      "Epoch 5/33, Train Loss: 0.9139    Valid Loss: 1.0299, Duration: 0:02:18.799384\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 6/33, Train Loss: 0.8252    Valid Loss: 1.0881, Duration: 0:02:18.647260\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 7/33, Train Loss: 0.7331    Valid Loss: 1.0142, Duration: 0:02:18.805738\n",
      "Validation loss decreased (1.017023 --> 1.014225).  Saving model ...\n",
      "Epoch 8/33, Train Loss: 0.6573    Valid Loss: 1.0552, Duration: 0:02:18.859115\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 9/33, Train Loss: 0.5972    Valid Loss: 1.0447, Duration: 0:02:18.803868\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 10/33, Train Loss: 0.5232    Valid Loss: 1.0982, Duration: 0:02:18.718295\n",
      "Early Stopping counter: 3 out of 5\n",
      "Epoch 11/33, Train Loss: 0.4563    Valid Loss: 1.1286, Duration: 0:02:18.827330\n",
      "Early Stopping counter: 4 out of 5\n",
      "Epoch 12/33, Train Loss: 0.4097    Valid Loss: 1.1227, Duration: 0:02:18.766330\n",
      "Early Stopping counter: 5 out of 5\n",
      "Early stopping\n",
      "\n",
      "\n",
      "Train acc: 0.8236,\t Valid acc: 0.6929,\t Test acc: 0.6548\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "bert_model = RobertaModel.from_pretrained('roberta-base')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) ## 5\n",
    "\n",
    "\n",
    "\n",
    "  ## 6. Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 33\n",
    "\n",
    "  #early stop para,eters\n",
    "patience = 5\n",
    "counter_early_stop = 0\n",
    "best_score = None\n",
    "early_stop = False\n",
    "valid_loss_min = np.Inf\n",
    "delta=0.001  \n",
    "\n",
    "# STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_iter) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "\n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "  model.train()\n",
    "  for batch in train_iter:\n",
    "    \n",
    "      # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "\n",
    "    # set gradients to zero \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    train_loss.append(loss.item())\n",
    "    \n",
    "  train_loss=np.mean(train_loss)\n",
    "        \n",
    "  valid_loss=[]\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "      output= model(batch.data)\n",
    "      loss=criterion(output,batch.label)\n",
    "        \n",
    "      valid_loss.append(loss.item())\n",
    "\n",
    "    valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "  train_losses[epoch]= train_loss\n",
    "  valid_losses[epoch]= valid_loss\n",
    "  dt= datetime.now()-t0\n",
    "    #print(scheduler)\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "\n",
    "    ## Early Stopping\n",
    "  score = -valid_loss\n",
    "\n",
    "  if best_score is None:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      valid_loss_min = valid_loss\n",
    "        \n",
    "  elif score < best_score + delta:\n",
    "      counter_early_stop += 1\n",
    "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
    "      if counter_early_stop >= patience:\n",
    "          early_stop = True\n",
    "  else:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      counter_early_stop = 0\n",
    "      valid_loss_min = valid_loss\n",
    "\n",
    "  if early_stop:\n",
    "    print(\"Early stopping\")\n",
    "    break\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  #load model\n",
    "model.load_state_dict(torch.load('tuned_bert.pt'))\n",
    "train_acc = get_accuracy(train_iter, model)\n",
    "valid_acc = get_accuracy(valid_iter, model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCKVy_irC50D"
   },
   "source": [
    "## Running MobileBert without fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Id8HQrkzD0GC",
    "outputId": "c31c56d6-6023-47d4-dc71-d2bd63cb8fec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SentencePiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 23.4MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 30.0MB/s eta 0:00:01\r",
      "\u001b[K     |▉                               | 30kB 25.3MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 40kB 22.2MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 51kB 22.7MB/s eta 0:00:01\r",
      "\u001b[K     |█▊                              | 61kB 16.5MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 71kB 16.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 81kB 15.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 92kB 15.3MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 102kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 112kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 122kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 133kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 143kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 153kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 163kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 174kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 184kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 194kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 204kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 215kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 225kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████▊                         | 235kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 245kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▍                        | 256kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 266kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 276kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 286kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 296kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 307kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 317kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 327kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 337kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 348kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 358kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 368kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 378kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 389kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▌                    | 399kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▊                    | 409kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 419kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▍                   | 430kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 440kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 450kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 460kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 471kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 481kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 491kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 501kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▊                 | 512kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 522kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 532kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 542kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 552kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 563kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▌               | 573kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 583kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 593kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 604kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 614kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 624kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 634kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 645kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 655kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 665kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 675kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▊            | 686kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 696kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 706kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 716kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 727kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 737kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▌          | 747kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 757kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 768kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 778kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 788kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 798kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 808kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 819kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 829kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 839kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▍       | 849kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 860kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 870kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 880kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▋      | 890kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 901kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 911kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 921kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▊     | 931kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 942kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▎    | 952kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▋    | 962kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 972kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 983kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 993kB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 1.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 1.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 1.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 1.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 1.0MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▍| 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 1.1MB 15.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.1MB 15.7MB/s \n",
      "\u001b[?25hInstalling collected packages: SentencePiece\n",
      "Successfully installed SentencePiece-0.1.94\n"
     ]
    }
   ],
   "source": [
    "!pip install SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-ubQOcMD9Wx",
    "outputId": "7efe7c27-2567-42d1-be0a-4c7913438e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n"
     ]
    }
   ],
   "source": [
    "% pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mwOKjfREfff",
    "outputId": "68ce8b67-4395-4e6e-ae5f-b3509b1dd94e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.94)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "% pip install transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  from transformers import MobileBertTokenizer\n",
    "  tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "  max_length = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oOR4degC50E"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pT7PEbZUC50E"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHiJWWw-C50E"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ah_KWw6C50E"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-4DfcMeC50E"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu3hOII3C50E"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QWqICSOpC50E"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zkMMDIxCC50E",
    "outputId": "593eaded-d213-456a-d652-db4975c15975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0V7EmHMC50E",
    "outputId": "3def0261-c273-416f-8fcd-40ea22f8a2a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Train Loss: 1.6932    Valid Loss: 1.3212, Duration: 0:01:17.333682\n",
      "\n",
      "\n",
      "Train acc: 0.5656,\t Valid acc: 0.5563,\t Test acc: 0.5360\n"
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertModel\n",
    "bert_model = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) \n",
    "\n",
    "\n",
    "\n",
    "  #Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 5\n",
    "\n",
    "\n",
    "  # STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "  # STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    " \n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "model.train()\n",
    "for batch in train_iter:\n",
    "          \n",
    "      # forward pass\n",
    "  output= model(batch.data)\n",
    "  loss=criterion(output,batch.label)\n",
    "\n",
    "      # set gradients to zero \n",
    "  optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  train_loss.append(loss.item())\n",
    "    \n",
    "train_loss=np.mean(train_loss)\n",
    "        \n",
    "valid_loss=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "        \n",
    "    valid_loss.append(loss.item())\n",
    "\n",
    "  valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "train_losses[epoch]= train_loss\n",
    "valid_losses[epoch]= valid_loss\n",
    "dt= datetime.now()-t0\n",
    "print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "train_acc = get_accuracy(train_iter,model)\n",
    "valid_acc = get_accuracy(valid_iter,model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n",
    "torch.save(model.state_dict(), 'model_1ec.pt')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvVGRZufH0Lr"
   },
   "source": [
    "## Running Fine tuned model - MobileBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nhWIw8xOH0Lr"
   },
   "outputs": [],
   "source": [
    "from transformers import MobileBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  from transformers import MobileBertTokenizer\n",
    "  tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
    "  max_length = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSd0kWC_H0Ls"
   },
   "outputs": [],
   "source": [
    "def bert_tokenizer(x):\n",
    "    tokens = tokenizer.tokenize(x) \n",
    "    tokens1 = tokens[:70-1]\n",
    "    tokens2 = tokens[-(70-1):]\n",
    "    tokens=tokens1+tokens2\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sGImstNMH0Ls"
   },
   "outputs": [],
   "source": [
    "n_hidden = 256 \n",
    "n_rnnlayers = 3 \n",
    "n_outputs =20 \n",
    "bidirectional = True \n",
    "dropout_rate = 0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1l1MbD6H0Ls"
   },
   "outputs": [],
   "source": [
    "TEXT = ttd.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = bert_tokenizer,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = tokenizer.cls_token_id,\n",
    "                  eos_token = tokenizer.sep_token_id,\n",
    "                  pad_token = tokenizer.pad_token_id,\n",
    "                  unk_token = tokenizer.unk_token_id)\n",
    "LABEL = ttd.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZEBjvIV4H0Ls"
   },
   "outputs": [],
   "source": [
    "train_dataset = ttd.TabularDataset(\n",
    "        'train.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HQhxaR1KH0Ls"
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TotRTP7SH0Ls"
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(100000000)\n",
    "test_dataset = ttd.TabularDataset(\n",
    "        'test.csv',\n",
    "        format='csv',\n",
    "        skip_header=True,\n",
    "        fields=[('data', TEXT), ('label', LABEL)]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uU2uLFSJH0Ls"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "SEED=123\n",
    "training_dataset, validation_dataset = train_dataset.split(split_ratio=0.8, random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wcNARxPxH0Ls",
    "outputId": "d885f0e6-c1c0-4f2e-860d-87b8ced10888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(training_dataset)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "train_iter, valid_iter, test_iter  = ttd.BucketIterator.splits((training_dataset,validation_dataset,test_dataset), \n",
    "                              sort_key=lambda x: len(x.data),\n",
    "                              #sort_key=None,\n",
    "                              batch_sizes=(16,128,128), \n",
    "                              device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2t6Ie57aH0Ls"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(data_iter, model):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    correct =0 \n",
    "    total =0\n",
    "    \n",
    "    for batch in data_iter:\n",
    "\n",
    "      output=model(batch.data)\n",
    "      _,indices = torch.max(output,dim=1)\n",
    "      correct+= (batch.label==indices).sum().item()\n",
    "      total += batch.label.shape[0]\n",
    "    \n",
    "    acc= correct/total\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSv4T47ZH0Ls"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate):\n",
    "      super(RNN, self).__init__()\n",
    "      self.D = bert_model.config.to_dict()['hidden_size']\n",
    "      self.bert_model = bert_model\n",
    "      \n",
    "      self.M = n_hidden\n",
    "      self.K = n_outputs\n",
    "      self.L = n_rnnlayers\n",
    "      self.num_diections= bidirectional\n",
    "      self.dropout_rate=dropout_rate\n",
    "      \n",
    "\n",
    "      \n",
    "      # rnn layers\n",
    "      self.rnn = nn.LSTM(\n",
    "          input_size=self.D,\n",
    "          hidden_size=self.M,\n",
    "          num_layers=self.L,\n",
    "          bidirectional=self.num_diections,\n",
    "          dropout= self.dropout_rate,\n",
    "          batch_first=True)\n",
    "      \n",
    "      # dense layer\n",
    "      self.fc = nn.Linear(self.M *2 , self.K)\n",
    "\n",
    "      # dropout layer\n",
    "      self.dropout= nn.Dropout(self.dropout_rate)\n",
    "    \n",
    "    def forward(self, X):\n",
    "      # initial hidden states\n",
    "      h0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "      c0 = torch.zeros(self.L*2, X.size(0), self.M).to(device)\n",
    "\n",
    "\n",
    "      with torch.no_grad():\n",
    "        embedding = self.bert_model(X)[0][:,1:,:]\n",
    "\n",
    "      embedding= self.dropout(embedding) # (batch_size, sentence_length, emd_dim)\n",
    "\n",
    "      # get RNN unit output\n",
    "      output, (hidden,cell) = self.rnn(embedding, (h0, c0))\n",
    "\n",
    "\n",
    "\n",
    "      # max pool\n",
    "      output, _ = torch.max(output, 1)\n",
    "      output= self.dropout(output)\n",
    "      # we only want h(T) at the final time step\n",
    "      output = self.fc(output)\n",
    "      return output  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6mYy_5YH0Ls"
   },
   "source": [
    "### MobileBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618,
     "referenced_widgets": [
      "f59932b379a044d1ad267c8d797f7cb7",
      "501d0c5d8dcc45298adc6d54bef02ca6",
      "2d78538d09ff46d5973a992c294b68cc",
      "48ac5f9e78c540dcb1c45472fa9ecd71",
      "a035ae1374d349e9ae1be1f4f3478d7e",
      "edcd9ba837d749c99a7a9f45537916cd",
      "13711d7f8b7e40bba010d0e270aa861f",
      "b6760aa4fe38402c81fbbf6214aef916",
      "933cd7981b7b432e8a81392799521810",
      "d6897526a00340ecbf13907bf677e012",
      "e053746f2c8c47c780591ea50a1ff2ea",
      "fc06988de7be4e72aad5dc89c08af34f",
      "64357231b27f4ccaaf31366167bc7630",
      "c3d2dcaef2744f39807b1cbed260138f",
      "626c173b2b664c51833fa7917cb90299",
      "50a1e17d939e4bc8ba1b4954d3ff836f"
     ]
    },
    "id": "43FTnP7tH0Ls",
    "outputId": "a72187d9-eb8b-465c-99d4-c90281d45376"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59932b379a044d1ad267c8d797f7cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=560.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933cd7981b7b432e8a81392799521810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=146671951.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/33, Train Loss: 1.6963    Valid Loss: 1.3182, Duration: 0:01:17.463451\n",
      "Validation loss decreased (inf --> 1.318207).  Saving model ...\n",
      "Epoch 2/33, Train Loss: 1.2602    Valid Loss: 1.2128, Duration: 0:01:17.254967\n",
      "Validation loss decreased (1.318207 --> 1.212790).  Saving model ...\n",
      "Epoch 3/33, Train Loss: 1.1140    Valid Loss: 1.1541, Duration: 0:01:17.280456\n",
      "Validation loss decreased (1.212790 --> 1.154071).  Saving model ...\n",
      "Epoch 4/33, Train Loss: 1.0428    Valid Loss: 1.0748, Duration: 0:01:17.190335\n",
      "Validation loss decreased (1.154071 --> 1.074802).  Saving model ...\n",
      "Epoch 5/33, Train Loss: 0.9697    Valid Loss: 1.0684, Duration: 0:01:17.220394\n",
      "Validation loss decreased (1.074802 --> 1.068407).  Saving model ...\n",
      "Epoch 6/33, Train Loss: 0.8901    Valid Loss: 1.0545, Duration: 0:01:17.109693\n",
      "Validation loss decreased (1.068407 --> 1.054536).  Saving model ...\n",
      "Epoch 7/33, Train Loss: 0.8380    Valid Loss: 1.0514, Duration: 0:01:17.205409\n",
      "Validation loss decreased (1.054536 --> 1.051398).  Saving model ...\n",
      "Epoch 8/33, Train Loss: 0.7811    Valid Loss: 1.0393, Duration: 0:01:17.243203\n",
      "Validation loss decreased (1.051398 --> 1.039334).  Saving model ...\n",
      "Epoch 9/33, Train Loss: 0.7125    Valid Loss: 1.0419, Duration: 0:01:17.155663\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epoch 10/33, Train Loss: 0.6668    Valid Loss: 1.0597, Duration: 0:01:16.935894\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epoch 11/33, Train Loss: 0.6152    Valid Loss: 1.0464, Duration: 0:01:16.853096\n",
      "Early Stopping counter: 3 out of 5\n",
      "Epoch 12/33, Train Loss: 0.5732    Valid Loss: 1.1250, Duration: 0:01:16.938606\n",
      "Early Stopping counter: 4 out of 5\n",
      "Epoch 13/33, Train Loss: 0.5241    Valid Loss: 1.0889, Duration: 0:01:16.911490\n",
      "Early Stopping counter: 5 out of 5\n",
      "Early stopping\n",
      "\n",
      "\n",
      "Train acc: 0.8104,\t Valid acc: 0.6818,\t Test acc: 0.6369\n"
     ]
    }
   ],
   "source": [
    "from transformers import MobileBertModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "bert_model = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n",
    "bert_model\n",
    "\n",
    "model = RNN(bert_model, n_hidden, n_rnnlayers, n_outputs, bidirectional, dropout_rate)\n",
    "model.to(device) ## 5\n",
    "\n",
    "\n",
    "\n",
    "  ## 6. Training loop\n",
    "import random\n",
    "\n",
    "seed = 123\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "learning_rate = 0.001\n",
    "epochs= 33\n",
    "\n",
    "  #early stop para,eters\n",
    "patience = 5\n",
    "counter_early_stop = 0\n",
    "best_score = None\n",
    "early_stop = False\n",
    "valid_loss_min = np.Inf\n",
    "delta=0.001  \n",
    "\n",
    "# STEP 5: INSTANTIATE LOSS CLASS\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "total_steps = len(train_iter) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "\n",
    "  # STEP 7: TRAIN THE MODEL\n",
    "\n",
    "train_losses= np.zeros(epochs)\n",
    "valid_losses= np.zeros(epochs)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "  t0= datetime.now()\n",
    "  train_loss=[]\n",
    "    \n",
    "  model.train()\n",
    "  for batch in train_iter:\n",
    "    \n",
    "      # forward pass\n",
    "    output= model(batch.data)\n",
    "    loss=criterion(output,batch.label)\n",
    "\n",
    "    # set gradients to zero \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "      # backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    train_loss.append(loss.item())\n",
    "    \n",
    "  train_loss=np.mean(train_loss)\n",
    "        \n",
    "  valid_loss=[]\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for batch in valid_iter:\n",
    "  \n",
    "        # forward pass\n",
    "      output= model(batch.data)\n",
    "      loss=criterion(output,batch.label)\n",
    "        \n",
    "      valid_loss.append(loss.item())\n",
    "\n",
    "    valid_loss=np.mean(valid_loss)\n",
    "    \n",
    "    # save Losses\n",
    "  train_losses[epoch]= train_loss\n",
    "  valid_losses[epoch]= valid_loss\n",
    "  dt= datetime.now()-t0\n",
    "    #print(scheduler)\n",
    "  print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}') \n",
    "\n",
    "    ## Early Stopping\n",
    "  score = -valid_loss\n",
    "\n",
    "  if best_score is None:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      valid_loss_min = valid_loss\n",
    "        \n",
    "  elif score < best_score + delta:\n",
    "      counter_early_stop += 1\n",
    "      print(f'Early Stopping counter: {counter_early_stop} out of {patience}')\n",
    "      if counter_early_stop >= patience:\n",
    "          early_stop = True\n",
    "  else:\n",
    "      best_score = score\n",
    "      print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "      torch.save(model.state_dict(),'tuned_bert.pt')\n",
    "      counter_early_stop = 0\n",
    "      valid_loss_min = valid_loss\n",
    "\n",
    "  if early_stop:\n",
    "    print(\"Early stopping\")\n",
    "    break\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "  #load model\n",
    "model.load_state_dict(torch.load('tuned_bert.pt'))\n",
    "train_acc = get_accuracy(train_iter, model)\n",
    "valid_acc = get_accuracy(valid_iter, model)\n",
    "test_acc = get_accuracy(test_iter ,model)\n",
    "print(\"\\n\")\n",
    "print(f'Train acc: {train_acc:.4f},\\t Valid acc: {valid_acc:.4f},\\t Test acc: {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BwoEPUMnImHD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "guw6ZNtaswKc",
    "hmCyX6aTj5ua",
    "aaWZaV2WCAwW",
    "VABLY8JCaCDP",
    "lHUQS6JCd-oK",
    "XTDqK-EYeI_m",
    "rtWnky-sfwWf",
    "huACUSnNgRKs",
    "rEQ61GKYhIWz",
    "hJH5US0ohagc",
    "E8Ow2t_iiCgp",
    "-FpjZrSuij3U",
    "dhaPICY0olTw",
    "2pNak9cHh4Vs",
    "_VIx243rNwFn",
    "lrFz5akaQH4m",
    "cCKVy_irC50D",
    "nvVGRZufH0Lr"
   ],
   "name": "Group_17_Project_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09ef3bbd5210439aaf9bbc25bdbabcc2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c4b526b07164a4ca784e8382ff91e6c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0c7478b09e6644a59c7694028224ae36": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1233d9b2c340408992071a3903decfae": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "16e5ba22bd8246d28e7d292b4ab31e31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae20b7c9834541ebbffcd0b6ad5ec768",
      "placeholder": "​",
      "style": "IPY_MODEL_ad8e78b4c3924f4691f1eae88c3158d7",
      "value": " 232k/232k [00:00&lt;00:00, 1.92MB/s]"
     }
    },
    "205f4b27f7d9481c893bd3a730e0d81f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30bc9a8e56b2420bb0743665ec2d643d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3121756c6bbf4d7da320f3b6b7b9241c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3186856ad0024e4886ab0a59fbcc767f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4116a13f25f64873a737bdd5c78f54e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "477a10aeadc241d2a3169f208090a20a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9534f0f1e5b4667a143cf1d448811e9",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d6c36207a1fa48fb88660c89fae2c77f",
      "value": 231508
     }
    },
    "477bba3b26584de9a479d927bf4c7165": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4d92a8a3d9914efe9e7d62840595c3bc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54104c04c82f4478882806cf224e1863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b316542b90ad46ab8313f1b64d2d4f73",
       "IPY_MODEL_d80f5624d5e646e29c298bc3703a54e0"
      ],
      "layout": "IPY_MODEL_79e74b279e6e4e50b607ac2cb807efd7"
     }
    },
    "5f6c04b440804499a91c06603272cd12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c0ae83c9b3c44993a0622b4cce1823ec",
       "IPY_MODEL_af436f5b83aa4e5ca0bd59286226d54f"
      ],
      "layout": "IPY_MODEL_60d2b433f3274e8c9c83606b87325f3c"
     }
    },
    "60d2b433f3274e8c9c83606b87325f3c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640a5b1585724de78c26593269c31bf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f21b73ce32114c6b950da3107b91509b",
       "IPY_MODEL_d21b670cde1a40e78dc9fdc8fa033c3f"
      ],
      "layout": "IPY_MODEL_3121756c6bbf4d7da320f3b6b7b9241c"
     }
    },
    "6f041b126599482a8f9664c61531278f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5a49914513b44b9b73d1ac8d0cb756d",
      "placeholder": "​",
      "style": "IPY_MODEL_30bc9a8e56b2420bb0743665ec2d643d",
      "value": " 232k/232k [00:00&lt;00:00, 2.19MB/s]"
     }
    },
    "79c117e842e24c9da587b602ebb0128c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "79e74b279e6e4e50b607ac2cb807efd7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c422a79ba164e5cb5046d014e4a13ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "887d172b7fb64478b06eceb5dfbda5a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_477a10aeadc241d2a3169f208090a20a",
       "IPY_MODEL_6f041b126599482a8f9664c61531278f"
      ],
      "layout": "IPY_MODEL_0c4b526b07164a4ca784e8382ff91e6c"
     }
    },
    "9eb3fae3298f41b6916f3baa32e12ad1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e4f1266b60424f09abdebaaf28700ef1",
       "IPY_MODEL_16e5ba22bd8246d28e7d292b4ab31e31"
      ],
      "layout": "IPY_MODEL_4d92a8a3d9914efe9e7d62840595c3bc"
     }
    },
    "ad8e78b4c3924f4691f1eae88c3158d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae20b7c9834541ebbffcd0b6ad5ec768": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af436f5b83aa4e5ca0bd59286226d54f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c7478b09e6644a59c7694028224ae36",
      "placeholder": "​",
      "style": "IPY_MODEL_3186856ad0024e4886ab0a59fbcc767f",
      "value": " 232k/232k [00:00&lt;00:00, 2.17MB/s]"
     }
    },
    "b316542b90ad46ab8313f1b64d2d4f73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_205f4b27f7d9481c893bd3a730e0d81f",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79c117e842e24c9da587b602ebb0128c",
      "value": 433
     }
    },
    "c0ae83c9b3c44993a0622b4cce1823ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2bc8aab01a24f51a8fe433422ec53e8",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1233d9b2c340408992071a3903decfae",
      "value": 231508
     }
    },
    "c2bc8aab01a24f51a8fe433422ec53e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cedc361a06614b44a693817654ef0ff1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d21b670cde1a40e78dc9fdc8fa033c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9743662f21c4276987c2764115621ce",
      "placeholder": "​",
      "style": "IPY_MODEL_477bba3b26584de9a479d927bf4c7165",
      "value": " 440M/440M [00:06&lt;00:00, 69.5MB/s]"
     }
    },
    "d6c36207a1fa48fb88660c89fae2c77f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d80f5624d5e646e29c298bc3703a54e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebf8642f3cde47be972a8309addc480f",
      "placeholder": "​",
      "style": "IPY_MODEL_4116a13f25f64873a737bdd5c78f54e8",
      "value": " 433/433 [00:00&lt;00:00, 14.2kB/s]"
     }
    },
    "e2a292b6a9a649ca901ed989a7060517": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e4f1266b60424f09abdebaaf28700ef1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cedc361a06614b44a693817654ef0ff1",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e2a292b6a9a649ca901ed989a7060517",
      "value": 231508
     }
    },
    "ebf8642f3cde47be972a8309addc480f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f21b73ce32114c6b950da3107b91509b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c422a79ba164e5cb5046d014e4a13ea",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09ef3bbd5210439aaf9bbc25bdbabcc2",
      "value": 440473133
     }
    },
    "f5a49914513b44b9b73d1ac8d0cb756d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9534f0f1e5b4667a143cf1d448811e9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f9743662f21c4276987c2764115621ce": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
